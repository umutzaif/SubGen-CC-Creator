# asr.py
from faster_whisper import WhisperModel
from pathlib import Path
import typer

def transcribe_audio(
    wav_file: str,
    model_size: str = "medium",
    language: str = "auto"
) -> list[dict]:
    wav_path = Path(wav_file)
    if not wav_path.exists():
        raise FileNotFoundError(f"Ses dosyasÄ± bulunamadÄ±: {wav_file}")

    typer.echo(f"ğŸ“ Transkripsiyon baÅŸlÄ±yor: {wav_file} (model={model_size}, dil={language})")

    # CPU iÃ§in ayar
    model = WhisperModel(model_size, device="cpu", compute_type="int8")

    segments, info = model.transcribe(
        str(wav_path),
        beam_size=5,
        language=None if language == "auto" else language
    )

    typer.echo(f"   AlgÄ±lanan dil: {info.language} (prob={info.language_probability:.2f})")

    results = []
    for seg in segments:
        results.append({
            "start": seg.start,
            "end": seg.end,
            "text": seg.text.strip()
        })

    typer.echo(f"âœ… Transkripsiyon tamamlandÄ±. {len(results)} segment bulundu.")
    return results
